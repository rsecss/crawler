import requests
from bs4 import BeautifulSoup

# ä¼ªè£…è‡ªå·±çš„è¯·æ±‚å¤´
header = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36 Edg/126.0.0.0'
}

count = 1

# æ‰“å¼€æ–‡ä»¶å‡†å¤‡å†™å…¥
with open('æ–—ç ´è‹ç©¹.txt','w',encoding='utf-8') as f:
    # å¾ªç¯éå†æŒ‡å®šèŒƒå›´é¡µé¢
    for start_num in range(20980,23273,1):
        url = f'https://www.kunnu.com/doupo/{start_num}.htm' # urlå¯ä»¥ä¿®æ”¹ï¼Œè¿™é‡Œæ˜¯ä»¥è¯¥åœ°å€ä¸ºä¾‹è¿›è¡ŒæŠ“å–
        
        # å‘é€è¯·æ±‚å¹¶è·å–å“åº”
        response = requests.get(url,headers=header)
        
        # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ
        if response.status_code == 200:
            html = response.text
            
            # ä½¿ç”¨ BeautifulSoup è§£æé¡µé¢
            soup = BeautifulSoup(html,"html.parser")
            
            #å¯»æ‰¾æ ‡é¢˜å¹¶æå–
            article = soup.find_all('article',class_='post clearfix')
            for content in article:
                # æå–æ ‡é¢˜å¹¶å±…ä¸­
                novel_title = content.header.h1.text
                centered_title = novel_title.center(60)  # 60 æ˜¯æ€»å®½åº¦ï¼Œå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´
                
                #æå–æ–‡ç« å†…å®¹
                novel_content = content.find('div',id='nr1').text
                novel_content_cleaned = novel_content.replace("é²²~å¼©~å°~è¯´~k u n n u - co m ğŸ’¨", "") # å»é™¤æŒ‡å®šå­—ç¬¦ä¸²
                
                # æ‰“å°æ ‡é¢˜å’Œå†…å®¹ï¼ˆå¯é€‰ï¼‰
                print(f'{count}. {centered_title}')
                print(novel_content_cleaned)
                print()  # æ‰“å°ç©ºè¡Œåˆ†éš”æ¯ç¯‡æ–‡ç« 
            
            #å†™å…¥æ–‡ä»¶å¹¶ä¿å­˜
            f.write(f'{centered_title}\n')
            f.write(f'{novel_content_cleaned}\n\n')
            count += 1

# è¾“å‡ºæç¤ºä¿¡æ¯
print("æŠ“å–æ•°æ®å¹¶ä¿å­˜åˆ°ã€Œæ–—ç ´è‹ç©¹.txtã€æ–‡ä»¶å®Œæˆã€‚")